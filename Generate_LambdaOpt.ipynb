{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f268370c-809b-4b88-95fa-ed1c985e969b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3915833b-3da2-40e8-919a-e1c233f1fb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.optimize import leastsq\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import statistics\n",
    "import math\n",
    "import time\n",
    "from tqdm import trange\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5f8760-25b6-441f-9aa0-dda0199d48c2",
   "metadata": {},
   "source": [
    "# Define Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7097c379-4f5d-42d2-ac45-9bce39fd5f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "SNR = 175\n",
    "n_elements = 128\n",
    "\n",
    "ob_weight = 100\n",
    "Nth = 10\n",
    "\n",
    "n_noise_realizations = 10\n",
    "n_datasets = 500\n",
    "\n",
    "lambdas = np.append(0, np.logspace(-7,3,51))\n",
    "\n",
    "upper_bound = [1,1,500,1500] #Set upper bound on parameters c1, c2, T21, T22, respectively\n",
    "initial = (0.5, 0.5, 250, 750) #Set initial guesses\n",
    "agg_array = np.array([1,1,1/ob_weight, 1/ob_weight])\n",
    "\n",
    "tdata = np.linspace(0, 635, n_elements)\n",
    "\n",
    "noise_sd = 1/SNR\n",
    "\n",
    "c1_set = np.array([0.1, 0.3, 0.5, 0.7, 0.9])\n",
    "c2_set = 1 - c1_set\n",
    "T21_set = np.array([10, 20, 30, 40, 50, 60])\n",
    "T22_set = np.array([70, 85, 100, 120, 150, 200])\n",
    "n_param_sets = c1_set.size * T21_set.size * T22_set.size\n",
    "\n",
    "SNR_set = np.array([10, 50, 100, 175, 300])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3a8f7f",
   "metadata": {},
   "source": [
    "# Define Signal Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5588df33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Two parameter definition of s(t) with regularization parameter lambda\n",
    "def G(t, con_1, con_2, tau_1, tau_2): \n",
    "    function = con_1*np.exp(-t/tau_1) + con_2*np.exp(-t/tau_2)\n",
    "    return function\n",
    "\n",
    "def G_tilde(lam, SA = 1):\n",
    "    #SA defines the signal amplitude, defaults to 1 for simulated data\n",
    "    def Gt_lam(t, con1, con2, tau1, tau2):\n",
    "        return np.append(G(t, con1, con2, tau1, tau2), [lam*con1/SA, lam*con2/SA, lam*tau1/ob_weight, lam*tau2/ob_weight])\n",
    "    return Gt_lam\n",
    "\n",
    "def noise(sd):\n",
    "    return np.random.normal(0, sd, n_elements)\n",
    "\n",
    "def add_noise(signal, SNR):\n",
    "    #Given a noiseless signal, adds noise at given SNR and returns a noisy signal\n",
    "    signal_length = len(signal)\n",
    "    noise_sd = signal[0]/SNR\n",
    "    noisy_signal = signal + np.random.normal(0, noise_sd, signal_length)\n",
    "    return noisy_signal\n",
    "\n",
    "def J(t, con1, con2, tau1, tau2):\n",
    "    func1 = np.exp(-t/tau1)\n",
    "    func2 = np.exp(-t/tau2)\n",
    "    func3 = (con1*t)*np.exp(-t/tau1)/(tau1**2)\n",
    "    func4 = (con2*t)*np.exp(-t/tau2)/(tau2**2)\n",
    "    jacobian = np.stack((func1, func2, func3, func4), axis=-1)\n",
    "    \n",
    "    return jacobian\n",
    "\n",
    "def cov_matrix(con1, con2, tau1, tau2, noise_sd):\n",
    "    jacobians = J(tdata, con1, con2, tau1, tau2).transpose()@J(tdata, con1, con2, tau1, tau2)\n",
    "    covariance = np.linalg.inv(jacobians)\n",
    "    return noise_sd**2*covariance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e37f540-222e-42ab-918a-e436b6e97ceb",
   "metadata": {},
   "source": [
    "# Define Regularization and Estimation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43b60872-c8dd-4044-9c7c-6e9f50e11653",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_parameters(data, lam):\n",
    "    data_tilde = np.append(data, [0,0,0,0])\n",
    "    \n",
    "    (rc1e, rc2e, rT21e, rT22e), rcov = curve_fit(G_tilde(lam), tdata, data_tilde, bounds = (0, upper_bound), p0=initial, max_nfev = 4000)\n",
    "    \n",
    "    if rT22e > rT21e:\n",
    "        c1est = rc1e\n",
    "        c2est = rc2e\n",
    "        T21est = rT21e\n",
    "        T22est = rT22e\n",
    "    else:\n",
    "        c1est = rc2e\n",
    "        c2est = rc1e\n",
    "        T21est = rT22e\n",
    "        T22est = rT21e\n",
    "        \n",
    "    return c1est, c2est, T21est, T22est\n",
    "\n",
    "def min_lambda(data, c1, c2, T21, T22, lambdas = np.logspace(-7, 3, 51), agg_arr = np.array([1, 1,1/ob_weight,1/ob_weight])):\n",
    "    #Finds the lambda which minimizes the total error of the NLLS estimates for a given data set\n",
    "    p_true = np.array([c1, c2, T21, T22])\n",
    "    abs_error_list = []\n",
    "    estimates = []\n",
    "    for lam in lambdas:\n",
    "        est = np.array(estimate_parameters(data, lam))\n",
    "        estimates.append(est)\n",
    "        error = np.absolute(est-p_true)\n",
    "        abs_error_list.append(error.dot(agg_arr))\n",
    "    \n",
    "    min_error_idx = np.argmin(abs_error_list)\n",
    "    min_error_est = estimates[min_error_idx]\n",
    "    min_error_lambda = lambdas[min_error_idx]\n",
    "\n",
    "    return min_error_est, min_error_lambda\n",
    "\n",
    "def oracle_lambda(c1, c2, T21, T22, data, lambdas, aggregate=False, wgt = np.array([1,1,0.01,0.01])):\n",
    "    n_lambdas = len(lambdas)\n",
    "    estimates = np.zeros((n_lambdas,4))\n",
    "    p_true = [c1, c2, T21, T22]\n",
    "    for l in range(n_lambdas):\n",
    "        lam = lambdas[l]\n",
    "        estimates[l,:] = estimate_parameters(data, lam)\n",
    "    error = np.absolute(estimates - p_true)\n",
    "    \n",
    "    if aggregate == True:\n",
    "        #If aggregating, returns the estimates which minimize the weighted sum of the error along with a single lambda\n",
    "        agg_error = error@wgt\n",
    "        min_agg_idx = np.argmin(agg_error)\n",
    "        min_agg_est = estimates[min_agg_idx,:]\n",
    "        min_lambda = lambdas[min_agg_idx]\n",
    "        return min_agg_est, min_lambda\n",
    "    if aggregate == False:\n",
    "        #If not aggregating, returns the estimates for each parameter which minimize their respective errors\n",
    "        #Also returns 4 lambdas, one for each of the 4 parameters\n",
    "        min_idx_array = np.argmin(error,axis=0)\n",
    "        min_est_array = estimates[min_idx_array,:]\n",
    "        min_lambdas_array = lambdas[min_idx_array]\n",
    "        return min_est_array, min_lambdas_array\n",
    "\n",
    "def min_bias_estimates(c1, c2, T21, T22, n=100, lambdas = np.logspace(-7,3, 51), agg_arr = [1,1,0.01,0.01]):\n",
    "    #Returns aggregate bias, variance, and MSE of the estimates generated \n",
    "    #from using the lambda which minimizes bias for each noise realization\n",
    "    agg_arr = np.array(agg_arr)\n",
    "    underlying = G(tdata, c1, c2, T21, T22)\n",
    "    \n",
    "    bias = np.zeros(4)\n",
    "    variance = np.zeros(4)\n",
    "    MSE = np.zeros(4)\n",
    "    \n",
    "    min_bias_lambdas = []\n",
    "    min_bias_estimates = []\n",
    "    for i in range(n):\n",
    "        np.random.seed(i)\n",
    "        data = underlying + noise(noise_sd)\n",
    "        agg_bias_list = []\n",
    "        temp_estimates = []\n",
    "        for l in range(len(lambdas)):\n",
    "            lam = lambdas[l]\n",
    "            est = np.array(estimate_parameters(data, lam))\n",
    "            temp_estimates.append(est)\n",
    "            agg_bias_list.append(np.absolute(est-[c1,c2,T21,T22]).dot(agg_arr))\n",
    "        \n",
    "        min_bias_idx = np.argmin(agg_bias_list)\n",
    "        \n",
    "        min_bias_lambdas.append(lambdas[min_bias_idx])\n",
    "        min_bias_estimates.append(temp_estimates[min_bias_idx])\n",
    "    \n",
    "    min_bias_estimates = np.array(min_bias_estimates)\n",
    "    \n",
    "    c1est = min_bias_estimates[:,0]\n",
    "    c2est = min_bias_estimates[:,1]\n",
    "    T21est = min_bias_estimates[:,2]\n",
    "    T22est = min_bias_estimates[:,3]\n",
    "    \n",
    "    bias[0] = (c1est - [c1]*n).sum()/n\n",
    "    bias[1] = (c2est - [c2]*n).sum()/n\n",
    "    bias[2] = (T21est - [T21]*n).sum()/n\n",
    "    bias[3] = (T22est - [T22]*n).sum()/n\n",
    "    \n",
    "    variance[0] = statistics.pvariance(c1est)\n",
    "    variance[1] = statistics.pvariance(c2est)\n",
    "    variance[2] = statistics.pvariance(T21est)\n",
    "    variance[3] = statistics.pvariance(T22est)\n",
    "    \n",
    "    MSE = bias**2 + variance\n",
    "    \n",
    "    agg_bias = np.absolute(bias).dot(agg_arr)\n",
    "    agg_variance = variance.dot(agg_arr**2)\n",
    "    agg_MSE = MSE.dot(agg_arr**2)\n",
    "    \n",
    "    return agg_bias, agg_variance, agg_MSE, np.array(min_bias_lambdas)\n",
    "\n",
    "def get_lam_selection_MSE_array(c1_set, c2_set, T21_set, T22_set, lambdas, lam_select, \n",
    "                                n=100, verbose=False, aggregate=False, safety_factor=2, model = None):\n",
    "    #Lam_select is either 'oracle', 'DP', 'GCV', or 'DNN'\n",
    "    #Defines which method is used to select lambda\n",
    "    n_c1 = len(c1_set)\n",
    "    n_c2 = len(c2_set)\n",
    "    n_T21 = len(T21_set)\n",
    "    n_T22 = len(T22_set)\n",
    "    n_params = n_c1*n_c2*n_T21*n_T22\n",
    "    n_lambdas = len(lambdas)\n",
    "    \n",
    "    MSE_array = np.zeros((n_c1,n_c2,n_T21,n_T22,4))\n",
    "    unreg_MSE_array = np.zeros((n_c1,n_c2,n_T21,n_T22,4))\n",
    "    improvement_array = np.zeros((n_c1,n_c2,n_T21,n_T22,4))\n",
    "    lambda_array = np.zeros((n_c1,n_c2,n_T21,n_T22,4))\n",
    "    iterator = 1\n",
    "    for ic1 in range(n_c1):\n",
    "        c1 = c1_set[ic1]\n",
    "        for ic2 in range(n_c2):\n",
    "            c2 = c2_set[ic2]\n",
    "            for iT21 in range(n_T21):\n",
    "                T21 = T21_set[iT21]\n",
    "                for iT22 in range(n_T22):\n",
    "                    T22 = T22_set[iT22]\n",
    "                    if verbose:\n",
    "                        print('Calculating combo', iterator, 'of', n_params)\n",
    "                        iterator+=1\n",
    "                    p_true = [c1, c2, T21, T22]\n",
    "                    underlying = G(tdata, c1, c2, T21, T22)\n",
    "                    estimates = np.zeros((n,4))\n",
    "                    estimates_unreg = np.zeros((n,4))\n",
    "                    for i in range(n):\n",
    "                        data = add_noise(underlying, SNR)\n",
    "                        if lam_select == 'oracle':\n",
    "                            lam = oracle_lambda(c1, c2, T21, T22, data, lambdas, aggregate=aggregate)[1]\n",
    "\n",
    "                        lambda_array[ic1,ic2,iT21,iT22,:] = lam\n",
    "                        est = estimate_parameters(data, lam)\n",
    "                        est_unreg = estimate_parameters(data, 0)\n",
    "                        estimates[i,:] = est\n",
    "                        estimates_unreg[i,:] = est_unreg\n",
    "                    \n",
    "                    bias = (estimates - p_true).sum(axis=0)/n\n",
    "                    variance = np.var(estimates, axis=0)\n",
    "                    MSE = variance + bias**2\n",
    "                    MSE_array[ic1,ic2,iT21,iT22,:] = MSE\n",
    "                    \n",
    "                    unreg_bias = (estimates_unreg - p_true).sum(axis=0)/n\n",
    "                    unreg_variance = np.var(estimates_unreg, axis=0)\n",
    "                    unreg_MSE = unreg_variance + unreg_bias**2\n",
    "                    unreg_MSE_array[ic1,ic2,iT21,iT22,:] = unreg_MSE\n",
    "                    \n",
    "                    improvement = (unreg_MSE - MSE)/unreg_MSE\n",
    "                    improvement_array[ic1,ic2,iT21,iT22,:] = improvement\n",
    "                    \n",
    "    return MSE_array, lambda_array, improvement_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f4eff8-f1a1-49e9-94e1-6b957a9de20d",
   "metadata": {},
   "source": [
    "# Generate Data Scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "841c5023-5990-4251-8f70-2e4776d5fd71",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [01:51<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\co\\NIA\\OptimalRegularizer\\Generate_LambdaOpt.ipynb Cell 10\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/co/NIA/OptimalRegularizer/Generate_LambdaOpt.ipynb#X12sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     data \u001b[39m=\u001b[39m data\u001b[39m/\u001b[39mdata[\u001b[39m0\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/co/NIA/OptimalRegularizer/Generate_LambdaOpt.ipynb#X12sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     datasets\u001b[39m.\u001b[39mappend(data)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/co/NIA/OptimalRegularizer/Generate_LambdaOpt.ipynb#X12sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     opt_params, min_error_lambdas \u001b[39m=\u001b[39m min_lambda(data, c1, c2, T21, T22)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/co/NIA/OptimalRegularizer/Generate_LambdaOpt.ipynb#X12sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     lambdaset\u001b[39m.\u001b[39mappend(min_error_lambdas)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/co/NIA/OptimalRegularizer/Generate_LambdaOpt.ipynb#X12sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m datasets \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(datasets)\n",
      "\u001b[1;32mc:\\co\\NIA\\OptimalRegularizer\\Generate_LambdaOpt.ipynb Cell 10\u001b[0m in \u001b[0;36mmin_lambda\u001b[1;34m(data, c1, c2, T21, T22, lambdas, agg_arr)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/co/NIA/OptimalRegularizer/Generate_LambdaOpt.ipynb#X12sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m estimates \u001b[39m=\u001b[39m []\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/co/NIA/OptimalRegularizer/Generate_LambdaOpt.ipynb#X12sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39mfor\u001b[39;00m lam \u001b[39min\u001b[39;00m lambdas:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/co/NIA/OptimalRegularizer/Generate_LambdaOpt.ipynb#X12sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     est \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(estimate_parameters(data, lam))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/co/NIA/OptimalRegularizer/Generate_LambdaOpt.ipynb#X12sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     estimates\u001b[39m.\u001b[39mappend(est)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/co/NIA/OptimalRegularizer/Generate_LambdaOpt.ipynb#X12sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     error \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mabsolute(est\u001b[39m-\u001b[39mp_true)\n",
      "\u001b[1;32mc:\\co\\NIA\\OptimalRegularizer\\Generate_LambdaOpt.ipynb Cell 10\u001b[0m in \u001b[0;36mestimate_parameters\u001b[1;34m(data, lam)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/co/NIA/OptimalRegularizer/Generate_LambdaOpt.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mestimate_parameters\u001b[39m(data, lam):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/co/NIA/OptimalRegularizer/Generate_LambdaOpt.ipynb#X12sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     data_tilde \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mappend(data, [\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m])\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/co/NIA/OptimalRegularizer/Generate_LambdaOpt.ipynb#X12sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     (rc1e, rc2e, rT21e, rT22e), rcov \u001b[39m=\u001b[39m curve_fit(G_tilde(lam), tdata, data_tilde, bounds \u001b[39m=\u001b[39;49m (\u001b[39m0\u001b[39;49m, upper_bound), p0\u001b[39m=\u001b[39;49minitial, max_nfev \u001b[39m=\u001b[39;49m \u001b[39m4000\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/co/NIA/OptimalRegularizer/Generate_LambdaOpt.ipynb#X12sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39mif\u001b[39;00m rT22e \u001b[39m>\u001b[39m rT21e:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/co/NIA/OptimalRegularizer/Generate_LambdaOpt.ipynb#X12sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m         c1est \u001b[39m=\u001b[39m rc1e\n",
      "File \u001b[1;32mc:\\co\\NIA\\.venv\\lib\\site-packages\\scipy\\optimize\\_minpack_py.py:800\u001b[0m, in \u001b[0;36mcurve_fit\u001b[1;34m(f, xdata, ydata, p0, sigma, absolute_sigma, check_finite, bounds, method, jac, **kwargs)\u001b[0m\n\u001b[0;32m    797\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mmax_nfev\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m kwargs:\n\u001b[0;32m    798\u001b[0m     kwargs[\u001b[39m'\u001b[39m\u001b[39mmax_nfev\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m'\u001b[39m\u001b[39mmaxfev\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m--> 800\u001b[0m res \u001b[39m=\u001b[39m least_squares(func, p0, jac\u001b[39m=\u001b[39mjac, bounds\u001b[39m=\u001b[39mbounds, method\u001b[39m=\u001b[39mmethod,\n\u001b[0;32m    801\u001b[0m                     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    803\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m res\u001b[39m.\u001b[39msuccess:\n\u001b[0;32m    804\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mOptimal parameters not found: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m res\u001b[39m.\u001b[39mmessage)\n",
      "File \u001b[1;32mc:\\co\\NIA\\.venv\\lib\\site-packages\\scipy\\optimize\\_lsq\\least_squares.py:928\u001b[0m, in \u001b[0;36mleast_squares\u001b[1;34m(fun, x0, jac, bounds, method, ftol, xtol, gtol, x_scale, loss, f_scale, diff_step, tr_solver, tr_options, jac_sparsity, max_nfev, verbose, args, kwargs)\u001b[0m\n\u001b[0;32m    924\u001b[0m     result \u001b[39m=\u001b[39m call_minpack(fun_wrapped, x0, jac_wrapped, ftol, xtol, gtol,\n\u001b[0;32m    925\u001b[0m                           max_nfev, x_scale, diff_step)\n\u001b[0;32m    927\u001b[0m \u001b[39melif\u001b[39;00m method \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtrf\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m--> 928\u001b[0m     result \u001b[39m=\u001b[39m trf(fun_wrapped, jac_wrapped, x0, f0, J0, lb, ub, ftol, xtol,\n\u001b[0;32m    929\u001b[0m                  gtol, max_nfev, x_scale, loss_function, tr_solver,\n\u001b[0;32m    930\u001b[0m                  tr_options\u001b[39m.\u001b[39;49mcopy(), verbose)\n\u001b[0;32m    932\u001b[0m \u001b[39melif\u001b[39;00m method \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mdogbox\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    933\u001b[0m     \u001b[39mif\u001b[39;00m tr_solver \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mlsmr\u001b[39m\u001b[39m'\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mregularize\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m tr_options:\n",
      "File \u001b[1;32mc:\\co\\NIA\\.venv\\lib\\site-packages\\scipy\\optimize\\_lsq\\trf.py:123\u001b[0m, in \u001b[0;36mtrf\u001b[1;34m(fun, jac, x0, f0, J0, lb, ub, ftol, xtol, gtol, max_nfev, x_scale, loss_function, tr_solver, tr_options, verbose)\u001b[0m\n\u001b[0;32m    119\u001b[0m     \u001b[39mreturn\u001b[39;00m trf_no_bounds(\n\u001b[0;32m    120\u001b[0m         fun, jac, x0, f0, J0, ftol, xtol, gtol, max_nfev, x_scale,\n\u001b[0;32m    121\u001b[0m         loss_function, tr_solver, tr_options, verbose)\n\u001b[0;32m    122\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 123\u001b[0m     \u001b[39mreturn\u001b[39;00m trf_bounds(\n\u001b[0;32m    124\u001b[0m         fun, jac, x0, f0, J0, lb, ub, ftol, xtol, gtol, max_nfev, x_scale,\n\u001b[0;32m    125\u001b[0m         loss_function, tr_solver, tr_options, verbose)\n",
      "File \u001b[1;32mc:\\co\\NIA\\.venv\\lib\\site-packages\\scipy\\optimize\\_lsq\\trf.py:296\u001b[0m, in \u001b[0;36mtrf_bounds\u001b[1;34m(fun, jac, x0, f0, J0, lb, ub, ftol, xtol, gtol, max_nfev, x_scale, loss_function, tr_solver, tr_options, verbose)\u001b[0m\n\u001b[0;32m    291\u001b[0m \u001b[39m# After all this has been done, we continue normally.\u001b[39;00m\n\u001b[0;32m    292\u001b[0m \n\u001b[0;32m    293\u001b[0m \u001b[39m# \"hat\" gradient.\u001b[39;00m\n\u001b[0;32m    294\u001b[0m g_h \u001b[39m=\u001b[39m d \u001b[39m*\u001b[39m g\n\u001b[1;32m--> 296\u001b[0m f_augmented[:m] \u001b[39m=\u001b[39m f\n\u001b[0;32m    297\u001b[0m \u001b[39mif\u001b[39;00m tr_solver \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mexact\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    298\u001b[0m     J_augmented[:m] \u001b[39m=\u001b[39m J \u001b[39m*\u001b[39m d\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#For each true parameter value, generate n_datasets at a certain SNR defined above\n",
    "iterator = 1\n",
    "for SNR in SNR_set:\n",
    "    noise_sd = 1/SNR\n",
    "    with h5py.File('Lambda_TrainingData//SNR_%s.hdf5'%SNR,'a') as f2:\n",
    "        for c1 in c1_set:\n",
    "            c2 = 1-c1\n",
    "            for iT21 in trange(np.size(T21_set)):\n",
    "                T21 = T21_set[iT21]\n",
    "                for T22 in T22_set:\n",
    "                    noiseless_curve = G(tdata, c1, c2, T21, T22)\n",
    "                    #Generate the datasets from the underlying curve\n",
    "                    datasets = []\n",
    "                    lambdaset = []\n",
    "                    for i in range(n_datasets):\n",
    "                        np.random.seed(i)\n",
    "                        data = noiseless_curve + noise(noise_sd)\n",
    "                        #For brain data, normalize so that the first point is at 1\n",
    "                        data = data/data[0]\n",
    "                        datasets.append(data)\n",
    "\n",
    "                        opt_params, min_error_lambdas = min_lambda(data, c1, c2, T21, T22)\n",
    "                        lambdaset.append(min_error_lambdas)\n",
    "    \n",
    "                    datasets = np.array(datasets)\n",
    "                    dset = f2.create_dataset('{},{},{},{},x'.format(c1,c2,T21,T22),data=datasets)\n",
    "                    dset = f2.create_dataset('{},y'.format(c1,c2,T21,T22),data=min_error_lambdas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98508698",
   "metadata": {},
   "source": [
    "# Alternative Generation Scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b2cd6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "c1_set = [0.5]\n",
    "c2_set = [0.5]\n",
    "T21_set = [10,20,30,40,50]\n",
    "T22_set = [70,90,110,130,150]\n",
    "\n",
    "oracle_MSE_array, oracle_lambda_array, oracle_imp_array = get_lam_selection_MSE_array(\n",
    "    c1_set, c2_set, T21_set, T22_set, lambdas, 'oracle', aggregate=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.4 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "b198fbbcfab0e745ebe2d4427d75efcc0bf102a681278e853c612d284d98e86b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
